{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoY0V6ztu5lOV2MwtWhgDn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-WlZ9YXT7rr1"},"outputs":[],"source":["# adjust optimizer lr to 0.007 + scheduler\n","import numpy as np\n","import pandas as pd\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader, random_split, TensorDataset\n","from torch.optim.lr_scheduler import StepLR\n","from PIL import Image\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","# auto. choose CPU or GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Function to load CIFAR-10 dataset\n","def load_cifar_batch(file):\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","\n","# Specify the directory containing CIFAR-10 batches\n","cifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n","\n","# Load metadata (labels)\n","meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n","label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n","\n","# Load training data\n","train_data = []\n","train_labels = []\n","for i in range(1, 6):\n","    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n","    train_data.append(batch[b'data'])\n","    train_labels += batch[b'labels']\n","\n","train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n","train_labels = np.array(train_labels)\n","\n","# Data augmentation and normalization\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n","    transforms.RandomRotation(10),\n","    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n","    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n","])\n","\n","# Convert to TensorDataset and apply transformations\n","class CustomCIFAR10Dataset(torch.utils.data.Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = self.images[idx]\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","train_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n","\n","# Split into training and validation sets\n","train_size = int(0.9 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n","\n","# Load test dataset\n","cifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n","test_batch = load_cifar_batch(cifar_test_path)\n","test_images = test_batch[b'data'].astype(np.float32) / 255.0\n","\n","test_transform = transforms.Compose([\n","    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n","])\n","\n","# Convert test dataset to Tensor\n","test_dataset = [(test_transform(img),) for img in test_images]\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n","\n","# Train function\n","def train_model(model, train_loader, val_loader, epochs=50):\n","    criterion = nn.CrossEntropyLoss()\n","    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n","    optimizer = optim.SGD(model.parameters(), lr=0.007, momentum=0.9, weight_decay=1e-4)\n","    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n","    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n","\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        scheduler.step()\n","        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n","\n","# Define a custom ResNet model from scratch\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.skip = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.skip = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","    def forward(self, x):\n","        identity = x\n","        if self.skip:\n","            identity = self.skip(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","        return out\n","\n","class CustomResNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(CustomResNet, self).__init__()\n","        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.init_bn = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_layer(64, 64, 6, stride=1)\n","        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride):\n","        layers = [ResidualBlock(in_channels, out_channels, stride)]\n","        for _ in range(1, blocks):\n","            layers.append(ResidualBlock(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.init_conv(x)\n","        out = self.init_bn(out)\n","        out = self.relu(out)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        #out = self.layer4(out)\n","        out = self.avg_pool(out)\n","        out = torch.flatten(out, 1)\n","        out = self.fc(out)\n","        return out\n","\n","# put models to devices (CPU/GPU)\n","model = CustomResNet().to(device)\n","\n","# Print the number of parameters\n","from torchsummary import summary\n","summary(model, (3, 32, 32))\n","\n","# Train the model\n","train_model(model, train_loader, val_loader, epochs=100) #change epoch\n","\n","# Generate submission file\n","model.eval()\n","predictions = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        predictions.extend(predicted.cpu().numpy())\n","\n","# Generate submission file\n","submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n","submission.to_csv('/kaggle/working/submission.csv', index=False)\n","print(\"Submission11 file saved.\")"]}]}